# -*- coding: utf-8 -*-
"""Pre_Trained_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_XRcipo3uDMqD-jmZnFJ2UtWUHL4j3bz
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
import os
import shutil
import zipfile
from pathlib import Path
import matplotlib.pyplot as plt
from google.colab import drive
from fastai.data.external import untar_data
from sklearn.model_selection import train_test_split
from torchvision.datasets import ImageFolder
from torch.utils.data import Subset
from collections import Counter
from google.colab import drive
from torch.optim.lr_scheduler import StepLR

drive.mount('/content/drive')

data_path = Path("/content/drive/MyDrive/Data_Work/imagenette2-160")

print(f"Dataset located at: {data_path}")
train_path = data_path / 'train'
print("Available classes:", os.listdir(train_path))

# Cell 3: Making the DataLoader and Preprocessing
from sklearn.model_selection import train_test_split
from torchvision.datasets import ImageFolder
from torch.utils.data import Subset

# Define transformations
train_transforms = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),
    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


test_val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


# Load the full dataset
full_dataset = ImageFolder(root='/content/drive/MyDrive/Data_Work/imagenette2-160/train', transform=train_transforms)

# Split into train (80%), validation (10%), and test (10%) sets
train_idx, test_val_idx = train_test_split(range(len(full_dataset)), test_size=0.2, random_state=42)
val_idx, test_idx = train_test_split(test_val_idx, test_size=0.5, random_state=42)

# Create subsets
train_dataset = Subset(full_dataset, train_idx)
val_dataset = Subset(full_dataset, val_idx)
test_dataset = Subset(full_dataset, test_idx)

# Update transforms for validation and test sets
val_dataset.dataset.transform = test_val_transforms
test_dataset.dataset.transform = test_val_transforms

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Print dataset sizes
print(f"Number of training images: {len(train_dataset)}")
print(f"Number of validation images: {len(val_dataset)}")
print(f"Number of testing images: {len(test_dataset)}")


# prompt: print number of images in each class

from collections import Counter

# Assuming 'full_dataset' is defined as in the provided code
class_counts = Counter([label for _, label in full_dataset.samples])

for class_name, count in class_counts.items():
    class_name_str = full_dataset.classes[class_name]
    print(f"Class '{class_name_str}': {count} images")

class B1Model(nn.Module):
    def __init__(self, num_classes):
        super(B1Model, self).__init__()
        self.backbone = models.resnet18(pretrained=False)
        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)

    def forward(self, x):
        return self.backbone(x)

num_classes = len(full_dataset.classes)
num_classes = 10
model = B1Model(num_classes=num_classes)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(model)

import torch
import numpy as np

class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""

    def __init__(self, patience=5, verbose=False, delta=0.0, path='checkpoint.pt'):
        """
        Args:
            patience (int): How long to wait after last time validation loss improved.
            verbose (bool): If True, prints a message for each validation loss improvement.
            delta (float): Minimum change in the monitored quantity to qualify as an improvement.
            path (str): Path to save the checkpoint model.
        """
        self.patience = patience
        self.verbose = verbose
        self.delta = delta
        self.path = path
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf

    def __call__(self, val_loss, model):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f"EarlyStopping counter: {self.counter} out of {self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        """Saves model when validation loss decreases."""
        if self.verbose:
            print(f"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...")
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        # Calculate average training loss
        avg_train_loss = running_loss / len(train_loader)

        # Validate the model after each epoch
        val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)

        # Print training loss and validation metrics
        print(f"Epoch [{epoch+1}/{num_epochs}] "
              f"Train Loss: {avg_train_loss:.4f} | "
              f"Validation Loss: {val_loss:.4f} | "
              f"Validation Accuracy: {val_accuracy:.2f}%")

def evaluate(model, val_loader, criterion, device):
    model.eval()
    running_val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)

            # Compute the loss
            loss = criterion(outputs, labels)
            running_val_loss += loss.item()

            # Compute the accuracy
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_val_loss = running_val_loss / len(val_loader)
    val_accuracy = 100 * correct / total
    return avg_val_loss, val_accuracy

optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)
train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')
plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)
plt.show()

# Plotting validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='green')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Validation Accuracy')
plt.legend()
plt.grid(True)
plt.show()

torch.save(model.state_dict(), 'b1.pth')

# prompt: take one image form the test_dataset and pridict its class with its acutall calss   Also print the original class name rather then the class id4

import matplotlib.pyplot as plt
import numpy as np

# Assuming test_dataset and model are defined as in the previous code
# Get a sample from the test dataset
image, label = test_dataset[56]  # Get the first image and its label

# Make a prediction
image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device
with torch.no_grad():
    outputs = model(image)
    _, predicted = torch.max(outputs, 1)

# Get the predicted and actual class names
predicted_class_id = predicted.item()
actual_class_id = label
predicted_class_name = full_dataset.classes[predicted_class_id]
actual_class_name = full_dataset.classes[actual_class_id]


# Display the image and print the predictions
plt.imshow(np.transpose(image.cpu().squeeze(0).numpy(), (1, 2, 0))) # Assuming your image is normalized and needs to be transposed back
plt.title(f"Predicted: {predicted_class_name}, Actual: {actual_class_name}")
plt.show()

# Cell 1: All Imports
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms, models
from sklearn.model_selection import train_test_split
import os
import matplotlib.pyplot as plt

# Cell 2: Download and Prepare the STL-10 Dataset with Train, Validation, and Test Splits
from torch.utils.data import random_split

# Define transformations
stl10_transforms = transforms.Compose([
     transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                         )
])

# Load the STL-10 training dataset (5000 labeled images)
full_train_dataset = datasets.STL10(root='./data', split='train', download=True, transform=stl10_transforms)

# Split the training data into 80% train and 20% validation
train_size = int(0.8 * len(full_train_dataset))
val_size = len(full_train_dataset) - train_size

train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])

# Load the STL-10 test dataset (8000 images)
test_dataset = datasets.STL10(root='./data', split='test', download=True, transform=stl10_transforms)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Print dataset sizes
print(f"Number of training images: {len(train_dataset)}")
print(f"Number of validation images: {len(val_dataset)}")
print(f"Number of testing images: {len(test_dataset)}")

# Cell 3: Define the B2 Model (CAFormer)
class CAFormer(nn.Module):
    def __init__(self, num_classes=10):
        super(CAFormer, self).__init__()
        # Load a pre-trained ResNet-18 model as the backbone
        self.backbone = models.resnet18(pretrained=True)
        # Replace the final fully connected layer with a new one for 10 classes
        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)

    def forward(self, x):
        return self.backbone(x)

# Instantiate the B2 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_classes = 10  # STL-10 has 10 classes
b2_model = CAFormer(num_classes=num_classes).to(device)

# Cell 4: Load Pre-Trained Weights from B1 Model
b1_weights_path = "b1.pth"

# Check if the B1 weights file exists
if os.path.exists(b1_weights_path):
    b2_model.load_state_dict(torch.load(b1_weights_path))
    print("B2 model initialized with B1 pre-trained weights.")
else:
    print("B1 weights file not found. Please train and save the B1 model first.")

# Cell 5a: Train and Validation Loop
def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device):
    model.train()
    running_train_loss = 0.0

    # Training Loop
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_train_loss += loss.item()

    avg_train_loss = running_train_loss / len(train_loader)

    # Validation Loop
    model.eval()
    running_val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            running_val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_val_loss = running_val_loss / len(val_loader)
    val_accuracy = 100 * correct / total

    return avg_train_loss, avg_val_loss, val_accuracy

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)

# Initialize lists to store losses and accuracies
num_epochs = 20
train_losses = []
val_losses = []
val_accuracies = []
test_accuracies = []

# Training, validation, and testing loop
for epoch in range(num_epochs):
    train_loss = train(model, train_loader, criterion, optimizer, device)
    val_loss, val_accuracy = validate(model, val_loader, criterion, device)
    test_accuracy = test(model, test_loader, device)  # Calculate test accuracy for each epoch

    # Store the results
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    val_accuracies.append(val_accuracy)
    test_accuracies.append(test_accuracy)

    # Print the losses and accuracies
    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Training Loss: {train_loss:.4f}, "
          f"Validation Loss: {val_loss:.4f}, "
          f"Validation Accuracy: {val_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

# Cell 6: Evaluate the B2 Model on the STL-10 Test Set
def evaluate(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f"Test Accuracy: {accuracy:.2f}%")

# Evaluate the fine-tuned B2 model
evaluate(b2_model, test_loader, device)

# Cell 7: Plot Training Loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss During Fine-Tuning')
plt.legend()
plt.grid(True)
plt.show()